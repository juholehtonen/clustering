\chapter{Background}
\label{chapter:background}

% Tiedonhankintaa suunnitellessasi voi miettiä vastauksia mm. 
% seuraaviin aiheen määrittelyä selventäviin tutkimuskysymyksiin:
% 
%     Mistä aiheesta tietoa tarvitaan?
%       bibliometriikasta, sen määritelmästä sekä klusteroinnista
%     Mihin tarkoitukseen tietoa tarvitaan?
%       Aiheen taustan kuvailuun, menetelmien kuvailuun ja 
%       valitun menetelmän toteuttamiseen
%     Mikä aiheessa on keskeistä?
%       Klusterointimenetelmän kokeilu ja tulosten raportointi
%     Mistä näkökulmasta aihetta lähestytään?
%       Käytännön implementaation kokeilulla
%     Mitä aiheesta tiedetään jo ennalta?
%       Klusteroinnista perusteet, bibliometriikasta vähemmän
%     Tarvitaanko yleis- vai tieteellistä tietoa?
%       Bibliometriikasta tarvitaan vähän yleistietoa, 
%       klusteroinnista tieteellistä.
%     Tarvitaanko kuva-aineistoa?
%       Ei muuta kuin itse tuotetut
%     Minkä ikäistä tietoa tarvitaan?
%       Yleis- ja taustatiedot vanhoista asioista, aiheen 
%       oleellinen tieto uusinta
%     Minkä kielistä tietoa tarvitaan?
%       suomi ja englanti käy


In this chapter we briefly introduce clustering and how it is 
positioned in the larger field of machine learning. But first we
describe what bibliometrics is.
% Taman esittelyjarjestyksen voi vaihtaa myohemmin

\section{Bibliometrics}
\label{sec:bibliometrics}
% Mita bibliometriikka on?
% Valmis --->-v
Bibliometrics is a study of written scientific records. The 
records may be books, articles, letters in scientific journals, 
conference papers and so on. Bibliometrics studies how these 
products of research are communicated, how are they related to 
each other, what kind of properties they have and what can be 
learned about the science in general by analysing them.

% Mihin bibliometriikka pyrkii vastaamaan?
Bibliometrics seeks to answer questions like ``How many 
publications have an author authored?'', ``What are the referred 
publications of a document?'', ``Which research area
does this publication belong to?'', ``What other publications 
belong to this research area?'', ``When has this research area
emerged?'', ``What are the most importatant related research areas
of this discipline?'' an so on. \fixme{Lisää yksinkertaisempia 
kysymyksiä}

% Background/history
% ==================
% Mika bibliometriikan historia on?
% OK --->-v
Classifying things is often the first thing we do when we observe 
the world. On the other hand counting the frequenzies of objects
and comparing these numbers often helps to put things in 
perspective.
% Tahan voisi laittaa sidontaa todennakoisyyslaskennalla tjsp.
One of the earliest studies that is generally considered
bibliometrics was Cole's and Eales' analysis to the anatomy 
literature in 1917 \cite{cole_history_1917}. In this study they 
researched the anatomy literature from 1543 through 1860 with the 
intention to graph the growth of of the number of documents over 
the three centuries, to present ``the performance'' of each 
European country, to observe the most popular topics among 
scholars from time to time, and to compare the advancement and 
devolution stages of the research with different societal 
events \cite{bellis_bibliometrics_2009}.
As the amount of scientific publications has enormously increased
the need to automatically analyze them has become apparent.
The basic analysis on top of which more detailed studies can be 
built on is classifying each publication to research areas and
disciplines.
% The need for some kind of bibliometric indices rise in the 
% First modern(?) classification was... by... some 
% indexing/publishing/to facilitate communication...
% At some point more and more automation was needed for bibliomterics
% There has been lot of study in automatically classificating the 
% science. 


\subsection{Classification in bibliometrics}
% Specific charasteristics of classifying the bibliometrics
% Miten bibliometriikkaa voidaan jasentaa / mista se koostuu?
% Existing classification systems / methods
% =========================================
Currently, the most popular systems to classify the publications 
into research areas are the Thomson 
Reuter's Web of Science and Elsevier's Scopus classification
systems. These classification systems classifies the journals into
one or more research areas. \cite{waltman_new_2012} Publications
are then classified to research ares based on which journal they
were published. \fixme{It is not known how these classifications 
are made exactly? Selvitä miten WOS ja Scopus luokittelut 
muodostetaan.}
Also an independent journal level classification system has been 
developed. \cite{archambault_towards_2011}
Journal level classification system have known limitations.
They are for example unable to meaningfully classify publications 
published in multidiscipline journals. 
Also some discipline specific classification systems exists such 
as (check them...).
An alternative classification system is publication level 
classification where each publication is classified based on some 
information extracted directly from the publication self such as
words used in the title and/or abstract, keywords attached by the
authors or publisher or citations to other publications.
Shu et al. have compared journal and paper level classification
approaches and found that publication level classification could
provide better classification \cite{shu_comparing_2019}.
% Usually classification of publications or journals can be approached 
% at least from multiple directions. There is clustering based method,
% the network based method and the combination of the two.
% In the network method

% ACM:n luokittelujärjestelmä esimerkkinä?
Bibliometric research 
uses mainly three types of methods; citation based, text analysis 
based or combination of the two \cite{janssens_hybrid_2009}.
Citation based methods study citations of publications and produce
networks publications as nodes connected by citation as edges.
Connection between two publications can be 
formed by a direct citation, bibliometric coupling where 
publications are connected when a third publication cites them 
both or co-citations where publications are connected if they 
cite the same third publication.

Text analysis based methods examine the title, the abstract or 
the whole text content of the publication itself and classifies 
the publications or journals by the topic model created 
\cite{blei_latent_2003}.
Hybrid models combine both approaches.

% Tama on kompelosti ilmaistu, korjaa
% Verkkoanalyysin nakokulma
% These research products and relations between them form a 
% network that can reveal something about the structure of 
% different scientific disciplines. Finding the structure of this 
% kind of data set is called classification or clustering.


% Previous results using clustering bibliometrics
% ===============================================
% Kirjoitettu yllä olevaan


\subsection{Bilbliometrics in Finland}
Ministry of Education and Culture of Finland provides yearly 
updated bibliometric analyses of Finnish research activities 
based on both Clarivative Analytics' Web Of Science citation 
index \cite[Vipunen service]{noauthor_ministry_2019} 
and Elsevier's Scopus database \cite[Vipunen 
service]{noauthor_ministry_2019-1}. The corresponding source 
system classification for field of science is used and 
aggregated to match the Statistics Finland classification. CSC - 
IT Center for Science provides the actual technical implementation 
of the service. \fixme{Pitää ehkä tarkentaa vielä, kysy YL:ltä}

Efforts to cluster Finnish research include a study by Korenius 
et al. analysing different hierarchical clustering methods but
applied to search query results \cite{korenius_hierarchical_2006}.
Suominen and Toivanen have researched clustering the Finnish
publications from years 1995-2011 using LDA... 
\cite{suominen_map_2016} \fixme{Selvennä että tämä ``kokeilevaa 
b. analyysia''}


\section{Clustering}
Classifying objects is a common task belonging to wider topic of 
machine learning. Methods can be divided to supervised and 
unsupervised. Supervised methods require the labels for the training
set. Unsupervised methods don't need any known labels for the data.
Unsupervised methods like clustering try to separate unrelated objects
into separate clusters and collect related objects into same cluster.

\fixme{Ero verkkoanalyysiin: lyhyesti}


\subsection{Choosing the number of clusters}
\fixme{Yleisellä tasolla: "tämän tyyppisiä menetelmiä on 
olemassa", "ne soveltuvat tähän ja tähän käyttötarkoitukseen". 
Helppo löytää ja käyttää viitteitä; esim. käytetty siinä ja siinä, 
meta- ja review-tutkimukset}

For K-means the choosing the number of clusters must be done before
the clustering. This is an unsolved problem. \fixme{citation}
Usually the 
problem is dealt by running the algorithm with various number of 
clusters and then measuring each by some metric. \fixme{citation}

In hierarchical clustering number of clusters can be chosen after 
the data has been clustered and the dendogram formed. 
\fixme{citation} By 
looking the dendogram and using different metrics the number of 
clustrs can be chosen.


\subsection{Evaluating of clustering results}
Calinski \& Harabazt criterion can be used as an evaluation 
criterion for deciding the number clusters \fixme{citation}. 

\subsubsection{Manually annotated validation set}
% Gold standard set. Actually a gold standard set would be a set
% of all data sets with abstract excluding sets that don't have it.
We will create a manually annotated validation set for calculating
precision, recall and metrics derived from those.
% määrittele peruskäsitteet kuten precision ja recall
The validation
set consists of $500$ publications from three different fields of
science, two more similar sub fields of computer science, 
information systems and artifical intelligence, and one more
distant from those, clinical neurology. \fixme{Kerro miten oma 
käsinryhmitelty aineisto muodostettu.}

Publications are inspected by title, abstract, keywords, journal
and publisher assinged disciplines of the journal. Publications
with critically missing data, unclear discipline assignment and
heavily applied publications were excluded from validation set.
Goal was to achieve evaluation measurements based on a quite 
clearly separated set of publications. More vaguely classificable
publications were included for comparison. For manually curated 
validation set with discipline assingment and justifications for
possible exclusion see appendix (Insert reference!).

When annotating publications, deciding if a publication belonged to
a discipline or not felt often quite difficult. Often the 
separation between disciplines felt quite arbitrary. For example
an article describing using wavelet transformation for coding noisy
images was decided to belong to CS information systems whereas an
article describing wavelet based corner detection using SVD was
decided to belong to CS artifical intelligence.
For CS artifical intelligence we mostly selected publications which
mentioned some dimensionalty reduction or machine learning related
term or concept.
CS information systems ended up being quite like some ``others'' or
``the rest'' dump class. It would have publications such as
``A reference model for conceptualising the convergence of 
telecommunications and datacommunications service platforms'',
``Developing a distributed meeting service to support mobile 
meeting participants'',
``On voice quality of IP voice over GPRS'',
