\chapter{Discussion}
\label{chapter:discussion}

The usefulness of our results lies in that they show how difficult
the task at hand is, and what aspects there are to consider when
approaching the problem.
% Alkuasetelma
The problem of defining how the science should be classified into
different disciplines is quite difficult and ambiguous.

% Datasta
The data was incomplete but we chose to use it as such without 
pruning the possible defective samples. This was due to the 
amount of data, manually checking over 20000 titles wasn't an 
option and sufficient general rules to filter the data didn't 
occur to us in the beginning of the work. Some minimum length for 
the publication data could leave out clearly inadequate samples 
and perhaps improve the clustering results. General outlier 
detection techniques \cite{hodge_survey_2004} could prove 
problematic here when there obviously will be single publications 
in some disciplines. There probably would be disciplines with very
few publications, in spite of including more data.

% Datan määrästä
We tried to include a larger data set, covering years 2000-2003, 
to cluster. This resulted $47303$ publications which was too much 
for our laptop environment with 16 GB of RAM. Obviously more 
capacity would have been available but taking over a new 
environment wasn't possible within the limits of this work.

% Piirreirroituksesta
Tokenization during pre-processing left one and two character 
words such as measurement units in data which wasn't desired. 
Adjusting tokenization or extending the stop word list should 
filter these out.
During vectorisation we hit our limit of maximum number of terms 
of $50000$. This might be undesirable because now our terms were
from the most frequent end of the frequency range of minimum $2$ 
occurrences -- maximum in $10 \%$ of documents. This means that 
rarer and thus more specific terms might have been discarded.
We tested some hand picked values of minimum and maximum document 
frequency threshold for terms but more systematic exploration of 
these parameters could have given better set of features.
%- \fixme{``Suositus...'' ``Nämä parametriarvot...''}
Furthermore, the discarded terms contained quite many compounds 
that were now joined with underscore '\_' to conserve the 
constructs. It might be worth to try and split those to enable the 
individual words to be counted.

% Ulottuvuuksien vähentämisestä
Selected number of components in reducing dimensionality of the 
data resulted quite low proportion of explained variance (35 \%).
%seemd to retain enough information while also allowing to run clustrings fast enough.
On the other hand, the resulting $800$ component low-dimensional
space is quite high dimensional too.
With the manually annotated data set the explained variance was 
100 \%. Yet the internal validation metrics gave insignificant 
values. This probably shows that $800$ dimensional data with just 
$455$ samples is still too high dimensional \cite{aggarwal_surprising_2001}. 
Selecting and extracting features more carefully and then reducing
dimensionality more could have helped.
Transforming data somewhere to $[50-150]$ components could be more
justified range \cite{dolnicar_review_2002}. 

% Model selection
The model selected, agglomerative Ward's clustering, is one of the
basic clustering methods. We selected it because it produces 
hierarchical cluster structure that is naturally expected of fields
and sub fields of science. It is not too sensitive to noise.
% while failing ...
It is known to work well only with compact, even-sized clusters.
This might be a problem with the current data where different 
disciplines are expected to be varying in size.
It can't cluster very large data sets because of the computational
cost. We might have bumped to that limit in a smaller scale while 
trying to cluster the four year data of ~47000 publications.

% Choosing the number of clusters
Choosing the number of clusters was a difficult part of this 
problem. We tried two internal validation methods,
Calinski-Harabasz criterion and silhouette values. Neither of them
could reveal any meaningful optimal clustering if any occurred.
Our manually annotated data set for choosing the number of clusters
was probably too small ($455$) compared to number of components 
($800$). 
It has been also noted that Calinski-Harabasz index 
might suffer even from moderate noise \cite{liu_understanding_2010}.
There are other internal clustering validation metrics that might 
work better with our data, one perhaps worth testing could be
S\_Dbw (Scatter and Density between clusters) index 
\cite{halkidi_clustering_2001}. 
It might also be that the merging of two computer science related 
sub fields into one cluster and clinical neurology splitting into 
two clusters can also result from the true properties of the data.
Perceived human definitions might not always match up with the 
underlying data. So there might be two sectors of clinical 
neurology represented in the data that are more distant from each 
other than these publications related to two computer science fields.

% Itse klusteroinnista
We didn't utilize the hierarchical structure of agglomerative 
clustering in this work. 
% We tried but didn't have time and didn't manage to to find out 
% how to extract and use the structure data.
It could have helped in deciding the number of clusters \cite{kimes_statistical_2017}.
% - Compared to current classification of articles into fields of 
% science based on WoS classification...

% Vertailu aiempaa suomalaiseen vastaavaan ``Suominen... et al.''
We could have very roughly compared our clustering to existing 
classification by calculating adjusted Rand index against WoS 
subject categories.
The question there would be how to automatically select WoS 
category for comparison for a publication that has several 
categories.

\section*{Conclusions}
\label{sec:conclusions}
We tried a basic clustering method to see if meaningful results
could be obtained. Some sensible clusters might have been formed 
but there appeared also totally mixed clusters which reduces the 
overall result as unsatisfactory.
% Toteutuksen heikkoudet ja vahvuudet
The clustering method was tested to the limit of our laptop 
environment with the amount of data.


\section*{Future work}
\label{sec:future}
In future work 2-grams or higher order n-grams could improve the 
results.

Using more data possibly with better scaling clustering method like 
K-means.
